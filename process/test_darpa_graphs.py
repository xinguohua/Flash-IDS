# =================è®­ç»ƒ=========================
import os
import pandas as pd
import torch
from process.datahandlers.common import collect_dot_paths
from process.make_graph import prepare_graph_new, collect_edges_from_log, \
    collect_nodes_from_log
from process.match.test_model import test_model
from process.model import EpochLogger, EpochSaver
from process.partition import detect_communities
from datahandlers.darpa_handler import collect_nodes_from_log,collect_edges_from_log
import re
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
all_dfs = []
all_netobj2pro = {}  # ç½‘ç»œå¯¹è±¡ UUID â†’ å±æ€§å­—ç¬¦ä¸²
all_subject2pro = {}  # è¿›ç¨‹ UUID â†’ å±æ€§å­—ç¬¦ä¸²
all_file2pro = {}  # æ–‡ä»¶ UUID â†’ å±æ€§å­—ç¬¦ä¸²

def merge_properties(src_dict, target_dict):
    for k, v in src_dict.items():
        if k not in target_dict:
            target_dict[k] = v

def collect_json_paths(base_dir):
    result = {}
    for subdir in os.listdir(base_dir):
        subdir_path = os.path.join(base_dir, subdir)
        if os.path.isdir(subdir_path):
            result[subdir] = {"benign": [], "malicious": []}
            for category in ["benign", "malicious"]:
                category_path = os.path.join(subdir_path, category)
                if os.path.exists(category_path):
                    for file in os.listdir(category_path):
                        if file.endswith(".json") and not file.startswith("._"):
                            full_path = os.path.join(category_path, file)
                            result[subdir][category].append(full_path)
    return result


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
logger = EpochLogger()
saver = EpochSaver()

# åŠ è½½ä¸€ä¸ªæ•°æ®é›†
base_path = "../data_files/theia"
json_map = collect_json_paths(base_path)

for scene, category_data in json_map.items():
    for category, json_files in category_data.items():
        # TODO: for test
        if scene != "theia33":
            continue

        print(f"æ­£åœ¨å¤„ç†: åœºæ™¯={scene}, ç±»åˆ«={category}, æ–‡ä»¶={json_files}")
        scene_category = f"/{scene}_{category}.txt"
        f = open(base_path + scene_category)

        # è®­ç»ƒåˆ†éš”
        data = f.read().split('\n')
        # TODO:
        # data = [line.split('\t') for line in data]
        # for test
        data = [line.split('\t') for line in data[:1000]]
        df = pd.DataFrame(data, columns=['actorID', 'actor_type', 'objectID', 'object', 'action', 'timestamp'])
        df = df.dropna()
        df.sort_values(by='timestamp', ascending=True, inplace=True)

        # å½¢æˆä¸€ä¸ªæ›´å®Œæ•´çš„è§†å›¾
        netobj2pro, subject2pro, file2pro = collect_nodes_from_log(json_files)
        df = collect_edges_from_log(df, json_files)
        # æ•°æ®é€‰æ‹©é€»è¾‘
        if category == "benign":
            # å–å10%
            num_rows = int(len(df) * 0.9)
            df = df.iloc[num_rows:]
            all_dfs.append(df)
        elif category == "malicious":
            # ä½¿ç”¨å…¨éƒ¨
            all_dfs.append(df)
            pass
        else:
            continue

        merge_properties(netobj2pro, all_netobj2pro)
        merge_properties(subject2pro, all_subject2pro)
        merge_properties(file2pro, all_file2pro)

# æµ‹è¯•ç”¨çš„æ•°æ®é›†
test_all_df = pd.concat(all_dfs, ignore_index=True)
test_all_df = test_all_df.drop_duplicates()
test_all_df.to_csv("test_all_df.txt", sep='\t', index=False)


def load_malicious_nodes(file_path):
    with open(file_path, 'r') as f:
        return set(line.strip() for line in f if line.strip())

def load_predictions(file_path):
    predictions = []
    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if line:  # ç¡®ä¿ä¸æ˜¯ç©ºè¡Œ
                predictions.append(int(line))
    return predictions

def evaluate_communities(communities, malicious_file, prediction_file):
    malicious_nodes = load_malicious_nodes(malicious_file)
    predictions = load_predictions(prediction_file)

    y_true = []
    y_pred = []

    tp = fp = tn = fn = 0

    for i in range(len(communities)):
        # === è·å–è¯¥ç¤¾åŒºçš„çœŸå®æ ‡ç­¾ ===
        is_true_malicious = any(node in malicious_nodes for node in communities[i])
        y_true.append(1 if is_true_malicious else 0)
        # === è·å–è¯¥ç¤¾åŒºçš„é¢„æµ‹æ ‡ç­¾ ===
        # æ³¨æ„ï¼šprediction_file ä¸­çš„é¡ºåºåº”ä¸ communities ä¸­èŠ‚ç‚¹é¡ºåºä¸€è‡´
        is_pred_malicious = any(predictions[i] == 1 for i, node in enumerate(communities[i]))
        y_pred.append(1 if is_pred_malicious else 0)

        if is_true_malicious and is_pred_malicious:
            tp += 1
        elif not is_true_malicious and is_pred_malicious:
            fp += 1
        elif is_true_malicious and not is_pred_malicious:
            fn += 1
        elif not is_true_malicious and not is_pred_malicious:
            tn += 1

    # === è®¡ç®—ç¤¾åŒºçº§è¯„ä¼°æŒ‡æ ‡ ===
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, zero_division=0)
    rec = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    try:
        auc = roc_auc_score(y_true, y_pred)
    except ValueError:
        auc = float('nan')
    fpr = fp / (fp + tn + 1e-10)

    print("\nğŸ“Š ç¤¾åŒºçº§åˆ«çš„è¯„ä¼°ç»“æœï¼š")
    print(f"âœ… Accuracy:  {acc:.4f}")
    print(f"âœ… Precision: {prec:.4f}")
    print(f"âœ… Recall:    {rec:.4f}")
    print(f"âœ… F1 Score:  {f1:.4f}")
    print(f"âœ… AUC:       {auc:.4f}")
    print(f"âœ… FPR:       {fpr:.4f}")
    print(f"âœ… TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}")

    return {
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1": f1,
        "auc": auc,
        "fpr": fpr,
        "tp": tp,
        "fp": fp,
        "fn": fn,
        "tn": tn
    }


def main():
    # ğŸ‘‡ æ›¿æ¢ä¸ºä½ çš„çœŸå®æ–‡ä»¶è·¯å¾„
    malicious_path = r"D:\æ•°æ®é›†åˆ†æ\Flash-IDS-main\MaliciousLabel\theia33_malicious.txt"
    prediction_path = r"D:\æ•°æ®é›†åˆ†æ\Flash-IDS-main\PredictionsAnswer\M1-CVE-2015-5122_windows_h1_prediction.txt"
    # âš ï¸ ç¡®ä¿ communities å·²åœ¨ä¸»ç¨‹åºä¸­å®šä¹‰ï¼ˆåœ¨ main å‡½æ•°å¤–çš„å…¨å±€å˜é‡ä¸­ï¼‰
    if 0 not in communities:
        print("é”™è¯¯ï¼šcommunities ä¸­ä¸åŒ…å«ç¼–å·ä¸º 0 çš„ç¤¾åŒºã€‚")
        return

    result = evaluate_communities(communities, malicious_path, prediction_path)

if __name__ == "__main__":
    features, edges, mapp, relations, G = prepare_graph_new(test_all_df, all_netobj2pro, all_subject2pro, all_file2pro)
    communities = detect_communities(G)
    num_nodes=len(communities[0])
    #print("ç¤¾åŒº 0 ä¸­çš„èŠ‚ç‚¹æ•°é‡ä¸º:", num_nodes)
    main()



